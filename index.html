<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <title>Mengdi Jia</title>
    <meta name="author" content="Mengdi Jia">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <body>
    <table style="width:100%;max-width:900px;border:0;border-spacing:0;margin:auto;">
      <tbody>
        <tr><td>

          <!-- Header -->
          <table style="width:100%;border:0;border-spacing:0;margin:auto;">
            <tr>
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align:center;font-size:32px;font-weight:bold;">Mengdi Jia</p>
                <p>
                  I am currently a mechatronics engineer based in Beijing. Previously, I received my Master's degree from 
                  <a href="https://www.ahau.edu.cn/">Anhui Agricultural University</a>, advised by Prof. <a href="https://jsxx.ahau.edu.cn/ch/jsxx_show.html?zgh=1994047">Chengmao Cao</a>,
                  and my Bachelor's degree from <a href="https://www.hebau.edu.cn/">Hebei Agricultural University</a>.
                  During my research internship at <a href="https://iiis.tsinghua.edu.cn/en/">Tsinghua University</a>, I contributed to projects including
                  <a href="https://qizekun.github.io/omnispatial/">OmniSpatial</a> and CTRL, working closely with
                  <a href="https://qizekun.github.io/">Zekun Qi</a>.
                </p>
                <p>My primary focus is on Embodied Intelligence, and Multimodal Large Language Models.</p>
                <p style="text-align:center">
                  <a href="mailto:mengdi__jia@163.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://au.cnki.net/author/personalInfo/000060962837?platform=kns-author">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/MengdiJia">GitHub</a> &nbsp;/&nbsp;
                  <a href="data/CV.pdf">CV</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/9E6A1316.png">
                  <img style="width:100%;object-fit:cover;border-radius:8px;" alt="profile photo" src="images/9E6A1316.png">
                </a>
              </td>
            </tr>
          </table>

          <!-- Publications -->
          <table style="width:100%;border:0;border-spacing:0;margin:auto;">
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
                <p><i>* indicates equal contribution</i></p>
              </td>
            </tr>
          </table>

          <table style="width:100%;border:0;border-spacing:0 10px;margin:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <img src="images/radar.png" width="160">
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://qizekun.github.io/omnispatial/">
                    <span class="papertitle">OmniSpatial: Towards Comprehensive Spatial Reasoning Benchmark for Vision Language Models</span>
                  </a>
                  <br>
                  <strong>Mengdi Jia</strong>, Zekun Qi*, Shaochen Zhang, Wenyao Zhang, XinQiang Yu, Jiawei He, He Wang, Li Yi
                  <br><i>Under review at NeurIPS 2025</i>
                  <p>
                    We present OmniSpatial, a benchmark for evaluating spatial reasoning abilities in vision-language models.
                    It covers four major categories and 50+ subtypes, totaling over 1.5K QA pairs. Experiments reveal significant
                    limitations in existing models and suggest directions for improvement.
                  </p>
                  <p>
                    [<a href="https://github.com/qizekun/OmniSpatial">GitHub</a>] /
                    [<a href="https://qizekun.github.io/omnispatial/">Project Page</a>] /
                    [<a href="https://huggingface.co/qizekun/datasets/OmniSpatial">Dataset</a>] /
                    [<a href="https://arxiv.org/abs/2506.03135">arXiv</a>] /
                    [<a href="https://arxiv.org/pdf/2506.03135">PDF</a>]
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- OmniSpatial Video -->
          <table style="width:100%;margin:auto;border:0;">
            <tr>
              <td style="padding:0;">
                <video width="100%" controls>
                  <source src="data/OmniSpatial.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
              </td>
            </tr>
          </table>

          <!-- Footer -->
          <table style="width:100%;margin:auto;border:0;">
            <tr>
              <td style="padding:0;">
                <br>
              </td>
            </tr>
          </table>

        </td></tr>
      </tbody>
    </table>
  </body>
</html>
